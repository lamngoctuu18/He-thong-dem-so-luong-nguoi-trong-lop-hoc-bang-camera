import os
import sys
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError
from sklearn.metrics import r2_score
import tensorflow as tf
from sklearn.model_selection import train_test_split

# Enable eager execution
tf.config.run_functions_eagerly(True)

# Add the parent directory to the system path to resolve the utils module
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from utils.data_preprocessing import load_labeled_data, preprocess_data, create_sequences, split_data
from lstm_model import build_lstm_model
from utils.plot_metrics import plot_metrics  # Import the new plot_metrics function

# Split data into training and validation sets
image_folder = '../data/images/'
label_folder = '../data/labels/'
split_data(image_folder, label_folder)

# Load training and validation data
train_label_folder = os.path.join(label_folder, 'train')
valid_label_folder = os.path.join(label_folder, 'valid')
df_train = load_labeled_data(train_label_folder)
df_valid = load_labeled_data(valid_label_folder)

if df_train.empty or df_valid.empty:
    print("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá sau khi x·ª≠ l√Ω.")
    exit()

# Chu·∫©n h√≥a d·ªØ li·ªáu
df_train, scaler_train = preprocess_data(df_train)
df_valid, scaler_valid = preprocess_data(df_valid)

# Chia d·ªØ li·ªáu th√†nh chu·ªói th·ªùi gian
X_train, y_train = create_sequences(df_train['people_count'].values)
X_valid, y_valid = create_sequences(df_valid['people_count'].values)

# Load ho·∫∑c t·∫°o m√¥ h√¨nh m·ªõi
try:
    model = load_model('C:/Project_Structure/data/trained_model.h5', custom_objects={'mse': MeanSquaredError()})
    print("‚úÖ Loaded existing model.")
    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics=['mae'])
except:
    model = build_lstm_model()
    model.compile(loss='mse', optimizer=Adam(learning_rate=0.0001), metrics=['mae'])
    print("üÜï Created new LSTM model.")

# Hu·∫•n luy·ªán m√¥ h√¨nh
history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_valid, y_valid), verbose=1)  # Reduced epochs to 50
model.save('data/trained_model.h5')

# ƒê√°nh gi√° m√¥ h√¨nh
y_pred = model.predict(X_train)
mae = MeanAbsoluteError()(y_train, y_pred).numpy()
r2 = r2_score(y_train, y_pred)
print(f"üìä ƒê·ªô l·ªói trung b√¨nh tuy·ªát ƒë·ªëi (MAE): {mae}")
print(f"‚úÖ H·ªá s·ªë x√°c ƒë·ªãnh (R¬≤ Score): {r2}")

# V·∫Ω bi·ªÉu ƒë·ªì hu·∫•n luy·ªán
plot_metrics(history, metric='loss')
plot_metrics(history, metric='mae')

print("üéâ Training ho√†n t·∫•t! M√¥ h√¨nh ƒë√£ l∆∞u v√†o 'data/trained_model.h5'")

